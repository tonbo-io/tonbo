use std::{collections::HashMap, sync::Arc};

use fusio::{
    DynFs,
    disk::LocalFs,
    executor::{Executor, Timer, tokio::TokioExecutor},
    fs::FsCas as FusioCas,
    mem::fs::InMemoryFs,
    path::{Path, PathPart},
};
use thiserror::Error;

use super::{DB, Mode};
use crate::{
    extractor::KeyExtractError,
    manifest::{ManifestError, TableId, TonboManifest, init_fs_manifest},
    wal::{
        WalConfig,
        state::{FsWalStateStore, WalStateStore},
    },
};

/// Builder-style configuration surface for constructing a [`DB`] instance.
///
/// The builder enforces that callers explicitly select a storage backend
/// (in-memory, local disk, or object storage) before the database can be
/// materialised. Additional wiring such as WAL configuration hooks and the
/// manifest bootstrap will be layered on top of this scaffolding in subsequent
/// steps.
pub struct DbBuilder<M>
where
    M: Mode,
{
    mode_config: M::Config,
    storage: Option<StorageBackendSpec>,
    wal_tuning: Option<Box<dyn FnMut(&mut WalConfig) + Send + 'static>>,
}

impl<M> DbBuilder<M>
where
    M: Mode,
{
    pub(super) fn new(mode_config: M::Config) -> Self {
        Self {
            mode_config,
            storage: None,
            wal_tuning: None,
        }
    }

    /// Select the in-memory storage backend, labelling the namespace with the
    /// provided identifier.
    #[must_use]
    pub fn in_memory(mut self, label: impl Into<String>) -> Self {
        self.set_storage(StorageBackendSpec::InMemory {
            label: label.into(),
        });
        self
    }

    /// Select a local filesystem backend rooted at `root`.
    #[must_use]
    pub fn on_disk(mut self, root: impl Into<String>) -> Self {
        self.set_storage(StorageBackendSpec::Disk { root: root.into() });
        self
    }

    /// Select an object-store backend using the provided configuration closure.
    #[must_use]
    pub fn on_object_store<F>(mut self, configure: F) -> Self
    where
        F: FnOnce(&mut ObjectStoreBuilder),
    {
        let mut builder = ObjectStoreBuilder::default();
        configure(&mut builder);
        self.set_storage(StorageBackendSpec::ObjectStore(builder.finish()));
        self
    }

    /// Allow advanced callers to tweak the autogenerated WAL configuration.
    #[must_use]
    pub fn configure_wal<F>(mut self, configure: F) -> Self
    where
        F: FnMut(&mut WalConfig) + Send + 'static,
    {
        self.wal_tuning = Some(Box::new(configure));
        self
    }

    fn set_storage(&mut self, spec: StorageBackendSpec) {
        if self.storage.is_some() {
            panic!("storage backend already selected");
        }
        self.storage = Some(spec);
    }

    /// Materialise a [`DB`] using the accumulated builder state.
    pub fn build(self) -> Result<DB<M, TokioExecutor>, DbBuildError> {
        let executor = Arc::new(TokioExecutor::default());
        self.build_with_executor(executor)
    }

    /// Materialise a [`DB`] using a caller-provided executor implementation.
    pub fn build_with_executor<E>(self, executor: Arc<E>) -> Result<DB<M, E>, DbBuildError>
    where
        E: Executor + Timer + Send + Sync + 'static,
    {
        self.build_internal(executor)
    }

    fn build_internal<E>(self, executor: Arc<E>) -> Result<DB<M, E>, DbBuildError>
    where
        M: Mode,
        E: Executor + Timer + Send + Sync + 'static,
    {
        let storage_spec = self.storage.ok_or(DbBuildError::MissingStorage)?;
        let layout = StorageLayout::new(storage_spec)?;
        let manifest_init = ManifestBootstrap::new(&layout);

        let (mode, mem) = M::build(self.mode_config).map_err(DbBuildError::Mode)?;
        let (manifest, manifest_table) = manifest_init.init_manifest()?;

        let mut wal_cfg = WalConfig::default();
        layout.apply_wal_defaults(&mut wal_cfg)?;
        if let Some(mut apply) = self.wal_tuning {
            apply(&mut wal_cfg);
        }

        Ok(DB::from_components(
            mode,
            mem,
            manifest,
            manifest_table,
            Some(wal_cfg),
            executor,
        ))
    }
}

/// Error returned when building a [`DB`] through [`DbBuilder`].
#[derive(Debug, Error)]
pub enum DbBuildError {
    /// No storage backend was selected prior to calling `build`.
    #[error("storage backend not selected")]
    MissingStorage,
    /// The provided storage root could not be parsed.
    #[error("invalid storage path `{path}`: {reason}")]
    InvalidPath {
        /// Path string that failed validation.
        path: String,
        /// Human-readable reason describing the failure.
        reason: String,
    },
    /// Object-store backends are not wired yet.
    #[error("object-store backend support not implemented")]
    UnsupportedObjectStore,
    /// Object-store configuration missing or invalid.
    #[error("object-store configuration error: {reason}")]
    ObjectStoreConfig {
        /// Human-readable explanation of the failure.
        reason: String,
    },
    /// Mode initialisation failed while building the DB.
    #[error(transparent)]
    Mode(#[from] KeyExtractError),
    /// Manifest initialisation failed while building the DB.
    #[error(transparent)]
    Manifest(#[from] ManifestError),
}

#[derive(Debug, Clone)]
pub(crate) enum StorageBackendSpec {
    InMemory { label: String },
    Disk { root: String },
    ObjectStore(ObjectStoreSpec),
}

/// Structured object-store specification captured by `DbBuilder`.
#[derive(Debug, Default, Clone)]
pub(crate) struct ObjectStoreSpec {
    pub(crate) provider: Option<String>,
    pub(crate) endpoint: Option<String>,
    pub(crate) bucket: Option<String>,
    pub(crate) root: Option<String>,
    pub(crate) access_key: Option<String>,
    pub(crate) secret_key: Option<String>,
    pub(crate) session_token: Option<String>,
    pub(crate) region: Option<String>,
    pub(crate) sign_payload: Option<bool>,
    pub(crate) checksum: Option<bool>,
    pub(crate) extra: HashMap<String, String>,
}

/// Mutable builder used to capture object-store options.
#[derive(Debug, Default)]
pub struct ObjectStoreBuilder {
    spec: ObjectStoreSpec,
}

impl ObjectStoreBuilder {
    /// Set the storage provider identifier (e.g. `"s3"`).
    pub fn provider(&mut self, provider: impl Into<String>) -> &mut Self {
        self.spec.provider = Some(provider.into());
        self
    }

    /// Set the endpoint URL for the object store backend.
    pub fn endpoint(&mut self, endpoint: impl Into<String>) -> &mut Self {
        self.spec.endpoint = Some(endpoint.into());
        self
    }

    /// Set the bucket/container name.
    pub fn bucket(&mut self, bucket: impl Into<String>) -> &mut Self {
        self.spec.bucket = Some(bucket.into());
        self
    }

    /// Set the logical root/prefix under which Tonbo will operate.
    pub fn root(&mut self, root: impl Into<String>) -> &mut Self {
        self.spec.root = Some(root.into());
        self
    }

    /// Set the access key used for authentication.
    pub fn access_key(&mut self, access_key: impl Into<String>) -> &mut Self {
        self.spec.access_key = Some(access_key.into());
        self
    }

    /// Set the secret key used for authentication.
    pub fn secret_key(&mut self, secret_key: impl Into<String>) -> &mut Self {
        self.spec.secret_key = Some(secret_key.into());
        self
    }

    /// Set the optional session token used for temporary credentials.
    pub fn session_token(&mut self, token: impl Into<String>) -> &mut Self {
        self.spec.session_token = Some(token.into());
        self
    }

    /// Set the AWS region for S3 backends.
    pub fn region(&mut self, region: impl Into<String>) -> &mut Self {
        self.spec.region = Some(region.into());
        self
    }

    /// Configure whether payload signing should be enforced for requests.
    pub fn sign_payload(&mut self, sign: bool) -> &mut Self {
        self.spec.sign_payload = Some(sign);
        self
    }

    /// Configure whether checksum validation should be enforced for uploads.
    pub fn checksum(&mut self, checksum: bool) -> &mut Self {
        self.spec.checksum = Some(checksum);
        self
    }

    /// Attach an arbitrary key/value option.
    pub fn option(&mut self, key: impl Into<String>, value: impl Into<String>) -> &mut Self {
        self.spec.extra.insert(key.into(), value.into());
        self
    }

    fn finish(self) -> ObjectStoreSpec {
        self.spec
    }
}

#[derive(Clone)]
struct StorageBackend {
    dyn_fs: Arc<dyn DynFs>,
    cas: Option<Arc<dyn FusioCas>>,
    root: Path,
    kind: StorageBackendKind,
}

#[derive(Clone)]
#[allow(dead_code)]
enum StorageBackendKind {
    InMemory { fs: Arc<InMemoryFs> },
    Disk { fs: Arc<LocalFs> },
    ObjectStore(ObjectStoreBackend),
}

#[derive(Clone)]
enum ObjectStoreBackend {
    S3 {
        fs: fusio::impls::remotes::aws::fs::AmazonS3,
    },
}

#[derive(Clone)]
struct StorageRoute {
    fs: Arc<dyn DynFs>,
    path: Path,
    cas: Option<Arc<dyn FusioCas>>,
}

#[cfg(test)]
mod tests {
    use std::collections::HashMap;

    use super::*;

    #[test]
    fn builds_s3_backend_with_minimal_config() {
        let spec = ObjectStoreSpec {
            provider: Some("s3".into()),
            endpoint: Some("http://localhost:9000".into()),
            bucket: Some("tonbo-test".into()),
            root: Some("tenant-a".into()),
            access_key: Some("access".into()),
            secret_key: Some("secret".into()),
            session_token: None,
            region: Some("us-east-2".into()),
            sign_payload: Some(true),
            checksum: Some(false),
            extra: HashMap::new(),
        };

        let backend = build_object_store_backend(spec).expect("s3 backend");
        match backend.kind {
            StorageBackendKind::ObjectStore(ObjectStoreBackend::S3 { .. }) => {}
            _ => panic!("unexpected backend kind"),
        }
    }
}

struct StorageLayout {
    backend: StorageBackend,
}

impl StorageLayout {
    fn new(spec: StorageBackendSpec) -> Result<Self, DbBuildError> {
        let backend = StorageBackend::from_spec(spec)?;
        Ok(Self { backend })
    }

    fn backend(&self) -> &StorageBackend {
        &self.backend
    }

    fn wal_route(&self) -> Result<StorageRoute, DbBuildError> {
        self.backend.route(StorageClass::Wal)
    }

    fn apply_wal_defaults(&self, cfg: &mut WalConfig) -> Result<(), DbBuildError> {
        let route = self.wal_route()?;
        cfg.dir = route.path.clone();
        cfg.segment_backend = Arc::clone(&route.fs);
        cfg.state_store = route
            .cas
            .map(|cas| Arc::new(FsWalStateStore::new(cas)) as Arc<dyn WalStateStore>);
        Ok(())
    }
}

#[derive(Debug, Clone, Copy, PartialEq, Eq, Hash)]
enum StorageClass {
    Wal,
}

impl StorageClass {
    fn components(self) -> &'static [&'static str] {
        match self {
            StorageClass::Wal => &["wal"],
        }
    }
}

impl StorageBackend {
    fn from_spec(spec: StorageBackendSpec) -> Result<Self, DbBuildError> {
        match spec {
            StorageBackendSpec::InMemory { label } => {
                if label.is_empty() {
                    return Err(DbBuildError::InvalidPath {
                        path: label,
                        reason: "label cannot be empty".into(),
                    });
                }
                let raw_fs = Arc::new(InMemoryFs::new());
                let dyn_fs: Arc<dyn DynFs> = raw_fs.clone();
                let cas_fs: Arc<dyn FusioCas> = raw_fs.clone();
                let root = Path::parse(&label).map_err(|err| DbBuildError::InvalidPath {
                    path: label,
                    reason: err.to_string(),
                })?;
                Ok(Self {
                    dyn_fs,
                    cas: Some(cas_fs),
                    root,
                    kind: StorageBackendKind::InMemory { fs: raw_fs },
                })
            }
            StorageBackendSpec::Disk { root } => {
                if root.is_empty() {
                    return Err(DbBuildError::InvalidPath {
                        path: root,
                        reason: "root cannot be empty".into(),
                    });
                }
                let raw_fs = Arc::new(LocalFs {});
                let dyn_fs: Arc<dyn DynFs> = raw_fs.clone();
                let cas_fs: Arc<dyn FusioCas> = raw_fs.clone();
                let root_path =
                    Path::from_filesystem_path(&root).map_err(|err| DbBuildError::InvalidPath {
                        path: root,
                        reason: err.to_string(),
                    })?;
                Ok(Self {
                    dyn_fs,
                    cas: Some(cas_fs),
                    root: root_path,
                    kind: StorageBackendKind::Disk { fs: raw_fs },
                })
            }
            StorageBackendSpec::ObjectStore(spec) => build_object_store_backend(spec),
        }
    }

    fn route(&self, class: StorageClass) -> Result<StorageRoute, DbBuildError> {
        let mut current = self.root.clone();
        for part in class.components() {
            let parsed = PathPart::parse(part).map_err(|err| DbBuildError::InvalidPath {
                path: part.to_string(),
                reason: err.to_string(),
            })?;
            current = current.child(parsed);
        }
        Ok(StorageRoute {
            fs: Arc::clone(&self.dyn_fs),
            path: current,
            cas: self.cas.clone(),
        })
    }

    fn kind(&self) -> &StorageBackendKind {
        &self.kind
    }

    fn root(&self) -> &Path {
        &self.root
    }
}

fn build_object_store_backend(spec: ObjectStoreSpec) -> Result<StorageBackend, DbBuildError> {
    let provider = spec
        .provider
        .as_deref()
        .unwrap_or("s3")
        .to_ascii_lowercase();

    match provider.as_str() {
        "s3" => build_s3_backend(spec),
        other => Err(DbBuildError::ObjectStoreConfig {
            reason: format!("unsupported object-store provider `{other}`"),
        }),
    }
}

fn build_s3_backend(spec: ObjectStoreSpec) -> Result<StorageBackend, DbBuildError> {
    use fusio::impls::remotes::aws::{credential::AwsCredential, fs::AmazonS3Builder};

    let mut extra = spec.extra;

    let bucket = spec.bucket.ok_or_else(|| DbBuildError::ObjectStoreConfig {
        reason: "bucket must be provided for s3 backends".into(),
    })?;

    let region = spec
        .region
        .or_else(|| extra.remove("region"))
        .unwrap_or_else(|| "us-east-1".into());
    let mut builder = AmazonS3Builder::new(bucket.clone()).region(region);

    if let Some(endpoint) = spec.endpoint {
        builder = builder.endpoint(endpoint);
    }

    let session_token = spec.session_token.or_else(|| extra.remove("session_token"));

    if let (Some(access_key), Some(secret_key)) = (spec.access_key, spec.secret_key) {
        let credential = AwsCredential {
            key_id: access_key,
            secret_key,
            token: session_token,
        };
        builder = builder.credential(credential);
    } else if session_token.is_some() {
        return Err(DbBuildError::ObjectStoreConfig {
            reason: "session token provided without access/secret keys".into(),
        });
    }

    let sign_flag = if let Some(flag) = spec.sign_payload {
        Some(flag)
    } else {
        take_extra_bool(&mut extra, "sign_payload")?
    };
    if let Some(sign) = sign_flag {
        builder = builder.sign_payload(sign);
    }

    let checksum_flag = if let Some(flag) = spec.checksum {
        Some(flag)
    } else {
        take_extra_bool(&mut extra, "checksum")?
    };
    if let Some(checksum) = checksum_flag {
        builder = builder.checksum(checksum);
    }

    let fs = builder.build();
    let root_input = spec.root.unwrap_or_default();
    let root = if root_input.is_empty() {
        Path::default()
    } else {
        Path::parse(&root_input).map_err(|err| DbBuildError::InvalidPath {
            path: root_input.clone(),
            reason: err.to_string(),
        })?
    };

    let dyn_fs: Arc<dyn DynFs> = Arc::new(fs.clone());
    let cas_fs: Arc<dyn FusioCas> = Arc::new(fs.clone());

    Ok(StorageBackend {
        dyn_fs,
        cas: Some(cas_fs),
        root,
        kind: StorageBackendKind::ObjectStore(ObjectStoreBackend::S3 { fs }),
    })
}

fn take_extra_bool(
    extra: &mut HashMap<String, String>,
    key: &str,
) -> Result<Option<bool>, DbBuildError> {
    if let Some(raw) = extra.remove(key) {
        match raw.to_ascii_lowercase().as_str() {
            "true" | "1" => Ok(Some(true)),
            "false" | "0" => Ok(Some(false)),
            other => Err(DbBuildError::ObjectStoreConfig {
                reason: format!("invalid boolean value `{other}` for `{key}`"),
            }),
        }
    } else {
        Ok(None)
    }
}

struct ManifestBootstrap<'a> {
    layout: &'a StorageLayout,
}

impl<'a> ManifestBootstrap<'a> {
    fn new(layout: &'a StorageLayout) -> Self {
        Self { layout }
    }

    fn init_manifest(&self) -> Result<(TonboManifest, TableId), DbBuildError> {
        let backend = self.layout.backend();
        match backend.kind() {
            StorageBackendKind::InMemory { fs } => {
                init_fs_manifest(Arc::as_ref(fs).clone(), backend.root(), 0)
                    .map_err(DbBuildError::Manifest)
            }
            StorageBackendKind::Disk { fs } => {
                init_fs_manifest(Arc::as_ref(fs).clone(), backend.root(), 0)
                    .map_err(DbBuildError::Manifest)
            }
            StorageBackendKind::ObjectStore(ObjectStoreBackend::S3 { fs }) => {
                init_fs_manifest(fs.clone(), backend.root(), 0).map_err(DbBuildError::Manifest)
            }
        }
    }
}
